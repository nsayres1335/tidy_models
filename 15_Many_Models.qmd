---
title: "Chapter 15: Screening Many Models"
format: html
date: last-modified
execute:
    cache: true
code-fold: true
toc: true
---

## 15.1. Modeling Concrete Mixture Strength

Data from Chap 10 of *Applied Predictive Modeling* (2013) by Kuhn and Johnson. The goal is to predict the compressive strength of concrete based on its ingredients.

*compressive_strength* - outcome variable
*age* - age (in days) of the concrete sample at testing
everything else - concrete components in kg/m\^3


```{r}
#| label: load-data

library(tidymodels)
tidymodels_prefer()
data(concrete, package = "modeldata")
glimpse(concrete)
```

In some cases, the same concrete formula was tested multiple times. Don't want to include replicate mixtures as individual datapoint since they might be distriubted across both the training and test sets - may inflate permorfance metrics. Taking the mean.

```{r}
#| label: remove-replicates

concrete <-
  concrete %>%
  group_by(across(-compressive_strength)) %>%
  summarize(compressive_strength = mean(compressive_strength), .groups = "drop")

nrow(concrete)
```

Default 3:1 split w/ 5 repeats of 10-fold CV.

```{r}
#| label: data-split

set.seed(1501)
concrete_split <- initial_split(concrete, strata = compressive_strength)
concrete_train <- training(concrete_split)
concrete_test <- testing(concrete_split)

set.seed(1502)
concrete_folds <-
  vfold_cv(concrete_train, strata = compressive_strength, repeats = 5)
```

Some models (e.g. NN, KNN, and SVM) require predictors to be centered and scaled. Other models, a traditional response surface design model expansion (i.e., quadratic and 2-way interactions) is a good idea. Creating 2 different recipes.

```{r}
#| label: create-recipes

normalized_rec <-
  recipe(compressive_strength ~ ., data = concrete_train) %>%
  step_normalize(all_predictors())

poly_recipe <-
  normalized_rec %>%
  step_poly(all_predictors()) %>%
  step_interact(~ all_predictors():all_predictors())
```

Using the **parsnip** addin to create a set of model specifications.

```{r}
#| label: model-specs

library(rules)
library(baguette)

linear_reg_spec <-
  linear_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")

nnet_spec <-
  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%
  set_engine("nnet", MaxNWts = 2600) %>%
  set_mode("regression")

mars_spec <-
  mars(prod_degree = tune()) %>% #<- use GCV to choose terms
  set_engine("earth") %>%
  set_mode("regression")

svm_r_spec <-
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

svm_p_spec <-
  svm_poly(cost = tune(), degree = tune()) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

knn_spec <-
  nearest_neighbor(
    neighbors = tune(),
    dist_power = tune(),
    weight_func = tune()
  ) %>%
  set_engine("kknn") %>%
  set_mode("regression")

cart_spec <-
  decision_tree(cost_complexity = tune(), min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("regression")

bag_cart_spec <-
  bag_tree() %>%
  set_engine("rpart", times = 50L) %>%
  set_mode("regression")

rf_spec <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_engine("ranger") %>%
  set_mode("regression")

xgb_spec <-
  boost_tree(
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    min_n = tune(),
    sample_size = tune(),
    trees = tune()
  ) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

cubist_spec <-
  cubist_rules(committees = tune(), neighbors = tune()) %>%
  set_engine("Cubist")
```

Kuhn and Johnson found that NN's should have up to 27 hidden units in the layer.

```{r}
#| label: nnet-param

nnet_param <-
  nnet_spec %>%
  extract_parameter_set_dials() %>%
  update(hidden_units = hidden_units(c(1, 27)))
```

## 15.2. Creating the Workflow Set

3 kinds of preprocessors: 1. standard R formula, 2. recipe object, and 3. dplyr-style selector.

```{r}
#| label: workflow-norm

normalized <-
  workflow_set(
    preproc = list(normalized = normalized_rec),
    models = list(
      SVM_radial = svm_r_spec,
      SVM_poly = svm_p_spec,
      KNN = knn_spec,
      neural_network = nnet_spec
    )
  )
normalized
```

Since there is only a single preprocessor, this function creates a set of workflows for each model. If there were more preprocessors, it would create all combinations of preprocessors and models.

Can *mutate()* the *wflow_id*. *info* contain a tibble with some identifiers and the workflow object.

```{r}
#| label: extract-workflow

normalized %>% extract_workflow(id = "normalized_KNN")
```

The *option* column is a placeholder for args when we evaluate workflow. E.g., adding the NN param object above.

```{r}
#| label: add-param-info

normalized <-
  normalized %>%
  option_add(param_info = nnet_param, id = "normalized_neural_network")

normalized
```

*result* column is a placeholder for output after tuning or resampling functions.

Other nonlinear models:

```{r}
#| label: workflow-nonlinear

# dplyr style selectors
model_vars <-
  workflow_variables(outcomes = compressive_strength, predictors = everything())

no_pre_proc <-
  workflow_set(
    preproc = list(simple = model_vars),
    models = list(
      MARS = mars_spec,
      CART = cart_spec,
      CART_bagged = bag_cart_spec,
      RF = rf_spec,
      boosting = xgb_spec,
      Cubist = cubist_spec
    )
  )

no_pre_proc
```

Assemble set that uses nonlinear terms and interactions with the appropriate models.

```{r}
#| label: features

with_features <-
  workflow_set(
    preproc = list(full_quad = poly_recipe),
    models = list(linear_reg = linear_reg_spec, KNN = knn_spec)
  )
```

Combing workflows.

```{r}
#| label: all-workflows

all_workflows <-
  bind_rows(no_pre_proc, normalized, with_features) %>%
  # Make the workflow ID's a little more simple:
  mutate(wflow_id = gsub("(simple_)|(normalized_)", "", wflow_id))

all_workflows
```

## Tuning and Evaluating the Models

*worflow_map()* function to tune each model in the workflow set. The default is *tune_grid()*. Grid search is applied to each workflow using up to 25 different para candidates.

```{r}
#| label: grid-tune-workflows
#| eval: false

grid_ctrl <-
  control_grid(
    save_pred = TRUE,
    parallel_over = "everything",
    save_workflow = TRUE
  )

# will take a couple hours to run
# grid_results <-
#    all_workflows %>%
#    workflow_map(
#       seed = 1503,
#       resamples = concrete_folds,
#       grid = 25,
#       control = grid_ctrl
#    )
```

Updates *option* and *result* columns. *tune[+]* and *rsmp[+]* mean no issues. 

*rank_results()* orders models by performance metric. Uses first metric in the metric set by default (RMSE here). Also, ranks all candidate sets. Can use *select_best* option of tank model using their best tune.

```{r}
#| label: view-grid-results
#| eval: false

grid_results %>%
  rank_results() %>%
  filter(.metric == "rmse") %>%
  select(model, .config, rmse = mean, rank)
```

Using *autoplot()* to viz performance.

```{r}
#| label: grid-plot
#| eval: false

autoplot(
  grid_results,
  rank_metric = "rmse", # <- how to order models
  metric = "rmse", # <- which metric to visualize
  select_best = TRUE # <- one point per workflow
) +
  geom_text(aes(y = mean - 1 / 2, label = wflow_id), angle = 90, hjust = 1) +
  lims(y = c(3.5, 9.5)) +
  theme(legend.position = "none")
```

Can view tuning param results for a specific model:

```{r}
#| label: cubist-plot

autoplot(grid_results, id = "Cubist", metric = "rmse")
```

## 15.4. Efficiently Screening Models

