---
title: "Tidy Modeling with R"
format: html
date: last-modified
execute:
    cache: true
code-fold: true
toc: true
---

## Intro

Code along with the [Tidy Modeling with R](https://www.tmwr.org/) book by Max Kuhn and Julia Silge.

## 4. Ames Housing Data

2,930 properties in Ames, Iowa.

```{r}
#| label: data

data(ames, package = "modeldata")
dim(ames)
```

74 columns covering house characteristics, locations, lot info, ratings, and sales prices.

```{r}
#| label: libraries
#| message: false

library(tidymodels)
tidymodels_prefer()
```

```{r}
#| label: distribution

ggplot(ames, aes(x = Sale_Price)) +
  geom_histogram(bins = 50)
```

Right skewed distribution. Let's log transform it.

```{r}
#| label: log-distribution

ggplot(ames, aes(x = Sale_Price)) +
  geom_histogram(bins = 50) +
  scale_x_log10()
```

More normal, better for inference.

```{r}
#| label: log-transform

ames <- ames |>
  mutate(Sale_Price = log10(Sale_Price))
```

Using log10 sale price from here on out.

## 5. Spending our Data

```{r}
#| label: set-seed

set.seed(501)
```

```{r}
#| label: split

ames_split <- initial_split(ames, prop = 0.8)
ames_split

ames_train <- training(ames_split)
ames_test <- testing(ames_split)

dim(ames_train)
```

There are `r dim(ames_train)[[1]]` and `r dim(ames_test)[[1]]` houses in the training and test sets. respectively.

```{r}
#| label: split-statrify

ames_split <- initial_split(ames, prop = 0.8, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
```

Stratified the split on `Sale_Price` since right skewed. Ensure similar distributions in training and test sets.

## 6. Fitting Model w/ Parsnip

```{r}
#| label: models

lm_model <- linear_reg() |>
  set_engine("lm")

lm_form_fit <- lm_model |>
  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)

lm_xy_fit <- lm_model |>
  fit_xy(
    x = ames_train |> select(Longitude, Latitude),
    y = ames_train |> pull(Sale_Price)
  )

lm_form_fit

lm_xy_fit
```

2 different ways to fit the same model: using a formula interface and using x/y interface.


```{r}
#| label: tidy

tidy(lm_form_fit)
```

tidy() in place of summary() for tidy results.

```{r}
#| label: predict

ames_test_small <- ames_test |> slice(1:5)

predict(lm_form_fit, new_data = ames_test_small)
```

Predicting on a subset of the test data.

```{r}
#| label: bind_pred

ames_test_small |>
  select(Sale_Price) |>
  bind_cols(predict(lm_form_fit, new_data = ames_test_small)) |>
  bind_cols(predict(lm_form_fit, ames_test_small, type = "pred_int"))
```

Binding predictions and prediction intervals to the actual sale prices.


```{r}
#| label: tree

tree_model <-
  decision_tree(min_n = 2) %>%
  set_engine("rpart") %>%
  set_mode("regression")

tree_fit <-
  tree_model %>%
  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)

ames_test_small %>%
  select(Sale_Price) %>%
  bind_cols(predict(tree_fit, ames_test_small))
```

Example of using a decision tree model instead of linear regression.

parsnip can support a lot more models ([see](https://parsnip.tidymodels.org/find/)).

Can use **parsnip_addin()** in RStudio to view list of poissible models for each model mode. Unfortunately however, Positron does not currently support RStudio addins.

## 7. Workflow Basics

Workflows help bundle pre-processing, fit, and post-proc steps.

```{r}
#| label: workflow-setup

lm_model <- linear_reg() |>
  set_engine("lm")

lm_wflow <- workflow() |>
  add_model(lm_model) |>
  add_formula(Sale_Price ~ Longitude + Latitude)
```

Adding model and pre-processing (formula) to the workflow.

```{r}
#| label: workflow-fit

lm_fit <- fit(lm_wflow, ames_train)
lm_fit
```

Workflows have a fit() method that cas be used to fit the model.


```{r}
#| label: workflow-predict

predict(lm_fit, ames_test |> slice(1:5))
```

Can also use predict() method on the fitted workflow.

```{r}
#| label: workflow-update

lm_fit |> update_formula(Sale_Price ~ Longitude)
```

Can update the workflow to change the formula or model.

```{r}
#| label: workflow-add-vars

lm_wflow <- lm_wflow |>
  remove_formula() |>
  add_variables(outcomes = Sale_Price, predictors = c(Longitude, Latitude))

lm_wflow
  ```

Can also add variables instead of a formula. Works w/ dplyr grammar. Facilitates more complex moedeling specs. Particularly useful w/ models such as glmnet and xgboost which expect user to make indicator vars from factor preds.


```{r}
#| label: handling-special-multilevel

# install.packages("multilevelmod")
library(multilevelmod)

multilevel_spec <- linear_reg() %>% set_engine("lmer")

multilevel_workflow <-
  workflow() %>%
  # Pass the data along as-is:
  add_variables(outcome = distance, predictors = c(Sex, age, Subject)) %>%
  add_model(
    multilevel_spec,
    # This formula is given to the model
    formula = distance ~ Sex + (age | Subject)
  )

multilevel_fit <- fit(multilevel_workflow, data = Orthodont)
multilevel_fit
```

Standard R methods can't properly process this formula. Workflows handles by using optional suplementary model forumla argument in add_model(). add_variable() specifies bare col names; add_model() takes the actual formula given to the model.

```{r}
#| label: handling-special-survival

# install.packages("censored")
library(censored)

parametric_spec <- survival_reg()

parametric_workflow <-
  workflow() %>%
  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) %>%
  add_model(parametric_spec, formula = Surv(futime, fustat) ~ age + strata(rx))

parametric_fit <- fit(parametric_workflow, data = ovarian)
parametric_fit
```

Another example using a survival analysis model.

```{r}
#| label: workflowsets-setup

library(workflowsets)

location <- list(
  longitude = Sale_Price ~ Longitude,
  latitude = Sale_Price ~ Latitude,
  coords = Sale_Price ~ Longitude + Latitude,
  neighborhood = Sale_Price ~ Neighborhood
)

location_models <-
  workflow_set(
    preproc = location,
    models = list(lm = lm_model)
  )

location_models

location_models$info[[1]]

extract_workflow(location_models, id = "coords_lm")
```

workflowsets package to create a set of workflows to compare different pre-processing and model combinations. Useful for finding best predictive models or assessing predictors.

```{r}
#| label: workflowsets-fit

location_models <- location_models |>
  mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train)))

location_models

location_models$fit[[1]]
```

Iterating info column to fit each workflow and mutating onto existing tibble for tidyness.

```{r}
#| label: eval-test-set

final_lm_res <- last_fit(lm_wflow, ames_split)
final_lm_res

fitted_lm_wflow <- extract_workflow(final_lm_res)

collect_metrics(final_lm_res)
collect_predictions(final_lm_res) %>% slice(1:5)
```

**last_fit()** convenience function to fit final model to entire training set and evaluate on the test set in one step. Returns a tibble with the fitted workflow, metrics, and predictions. Each have helper functions to extract/collect them.